{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_est(df, metric, plugin_metric, plugin_models, rscore_models):\n",
    "    plugin_cols = [f'{metric}_{pm}_{plugin_metric}' for pm in plugin_models]\n",
    "    rscore_cols = [f'{metric}_rs_{rs_bm}' for rs_bm in rscore_models]\n",
    "    cols = ['name', f'{metric}_mse', f'{metric}_r2', f'{metric}_mixed'] + plugin_cols + rscore_cols + [f'{metric}_test']\n",
    "    return df[cols]\n",
    "\n",
    "def show_base(df, metric, plugin_metric, plugin_models, rscore_models):\n",
    "    plugin_cols = [f'{metric}_{pm}_{plugin_metric}' for pm in plugin_models]\n",
    "    rscore_cols = [f'{metric}_rs_{rs_bm}' for rs_bm in rscore_models]\n",
    "    cols = ['name'] + plugin_cols + rscore_cols + [f'{metric}_test']\n",
    "    return df[cols]\n",
    "\n",
    "def show_all(df, metric, plugin_metrics, plugin_models, matching_ks, rscore_models):\n",
    "    plugin_cols = [f'{metric}_{pm}_{plugin_metric}' for plugin_metric in plugin_metrics for pm in plugin_models]\n",
    "    matching_cols = [f'{metric}_match_{k}k_{plugin_metric}' for plugin_metric in plugin_metrics for k in matching_ks]\n",
    "    rscore_cols = [f'{metric}_rs_{rs_bm}' for rs_bm in rscore_models]\n",
    "    cols = ['name', f'{metric}_mse', f'{metric}_r2'] + plugin_cols + matching_cols + rscore_cols + [f'{metric}_test']\n",
    "    return df[cols]\n",
    "\n",
    "def show_all_jobs(df, metric, plugin_metrics, plugin_models, matching_ks, rscore_models):\n",
    "    plugin_cols = [f'{metric}_{pm}_{plugin_metric}' for plugin_metric in plugin_metrics for pm in plugin_models]\n",
    "    matching_cols = [f'{metric}_match_{k}k_{plugin_metric}' for plugin_metric in plugin_metrics for k in matching_ks]\n",
    "    rscore_cols = [f'{metric}_rs_{rs_bm}' for rs_bm in rscore_models]\n",
    "    cols = ['name', f'{metric}_mse', f'{metric}_r2', f'{metric}_pol'] + plugin_cols + matching_cols + rscore_cols + [f'{metric}_test']\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_filter(x, metric):\n",
    "    if x[f'{metric}_mse'] != '-':\n",
    "        return x[f'{metric}_mse']\n",
    "    elif x[f'{metric}_mixed'] != '-':\n",
    "        return x[f'{metric}_mixed']\n",
    "    else:\n",
    "        return x[f'{metric}_rs_lgbm']\n",
    "\n",
    "def ate_filter(x):\n",
    "    return my_filter(x, 'ate')\n",
    "\n",
    "def pehe_filter(x):\n",
    "    return my_filter(x, 'pehe')\n",
    "\n",
    "def att_filter(x):\n",
    "    return my_filter(x, 'att')\n",
    "\n",
    "def policy_filter(x):\n",
    "    return my_filter(x, 'policy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IHDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plugin_meta_models = ['sl', 'tl']\n",
    "#plugin_base_models = ['dt', 'lgbm', 'cb']\n",
    "plugin_base_models = ['dt', 'lgbm', 'kr']\n",
    "plugin_models = [f'{pmm}_{pbm}' for pmm in plugin_meta_models for pbm in plugin_base_models]\n",
    "matching_ks = [1, 3, 5]\n",
    "#rscore_base_models = ['dt', 'lgbm', 'cb']\n",
    "rscore_base_models = ['dt', 'lgbm', 'kr']\n",
    "\n",
    "ds = 'ihdp'\n",
    "avg_metric = 'ate'\n",
    "ite_metric = 'pehe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective -- causal estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "  name &   selection_ate &        ate_test &  selection_pehe &       pehe_test \\\\\n",
      "\\midrule\n",
      "    SL & $0.246\\pm0.098$ & $0.001\\pm0.001$ & $1.373\\pm0.612$ & $1.205\\pm0.561$ \\\\\n",
      "    TL & $0.168\\pm0.098$ & $0.000\\pm0.000$ & $0.701\\pm0.202$ & $0.621\\pm0.200$ \\\\\n",
      " IPSWS & $0.131\\pm0.034$ & $0.001\\pm0.000$ & $1.552\\pm0.726$ & $1.204\\pm0.560$ \\\\\n",
      "   DRS & $0.211\\pm0.079$ & $0.002\\pm0.001$ & $1.470\\pm0.624$ & $1.275\\pm0.581$ \\\\\n",
      "  DMLS & $0.438\\pm0.136$ & $0.007\\pm0.003$ & $1.905\\pm0.826$ & $1.679\\pm0.830$ \\\\\n",
      "    XL & $0.270\\pm0.135$ & $0.009\\pm0.007$ & $1.276\\pm0.448$ & $1.067\\pm0.409$ \\\\\n",
      "    CF & $0.240\\pm0.129$ & $0.198\\pm0.131$ & $2.295\\pm1.185$ & $2.290\\pm1.186$ \\\\\n",
      "SL-MLP & $0.486\\pm0.128$ & $0.104\\pm0.038$ & $1.064\\pm0.212$ & $0.925\\pm0.224$ \\\\\n",
      "TL-MLP & $0.221\\pm0.076$ & $0.000\\pm0.000$ & $0.894\\pm0.183$ & $0.641\\pm0.190$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1586278/1977360805.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ate['selection'] = df_ate.apply(ate_filter, axis=1)\n",
      "/tmp/ipykernel_1586278/1977360805.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pehe['selection'] = df_pehe.apply(pehe_filter, axis=1)\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv(f'./tables/{ds}_compare_metrics_meta_est_sem_latex.csv')\n",
    "df_all['name'] = df_all['name'].apply(lambda x: x.upper().replace('_', '-'))\n",
    "\n",
    "df_ate = show_est(df_all, avg_metric, 'ate', plugin_models, rscore_base_models)\n",
    "df_pehe = show_est(df_all, ite_metric, 'pehe', plugin_models, rscore_base_models)\n",
    "\n",
    "df_ate['selection'] = df_ate.apply(ate_filter, axis=1)\n",
    "df_pehe['selection'] = df_pehe.apply(pehe_filter, axis=1)\n",
    "\n",
    "df_merged = df_ate.merge(df_pehe, on=['name'], suffixes=['_ate', '_pehe'])\n",
    "print(df_merged[['name', 'selection_ate', 'ate_test', 'selection_pehe', 'pehe_test']].to_latex(index=False, escape=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective -- base learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "  name &   selection_ate &        ate_test &  selection_pehe &       pehe_test \\\\\n",
      "\\midrule\n",
      "    L1 & $0.340\\pm0.129$ & $0.046\\pm0.016$ & $1.795\\pm0.881$ & $1.643\\pm0.884$ \\\\\n",
      "    L2 & $0.270\\pm0.142$ & $0.161\\pm0.112$ & $1.810\\pm0.899$ & $1.603\\pm0.841$ \\\\\n",
      "    DT & $0.399\\pm0.202$ & $0.000\\pm0.000$ & $2.330\\pm1.028$ & $1.890\\pm0.932$ \\\\\n",
      "    RF & $0.253\\pm0.095$ & $0.020\\pm0.011$ & $1.909\\pm0.968$ & $1.529\\pm0.811$ \\\\\n",
      "    ET & $0.292\\pm0.129$ & $0.003\\pm0.002$ & $1.999\\pm1.107$ & $1.582\\pm0.915$ \\\\\n",
      "    KR & $0.282\\pm0.104$ & $0.001\\pm0.001$ & $1.399\\pm0.623$ & $0.653\\pm0.195$ \\\\\n",
      "    CB & $0.267\\pm0.064$ & $0.004\\pm0.002$ & $1.453\\pm0.700$ & $0.893\\pm0.386$ \\\\\n",
      "  LGBM & $0.264\\pm0.080$ & $0.016\\pm0.008$ & $1.881\\pm0.907$ & $1.326\\pm0.562$ \\\\\n",
      "    CF & $0.240\\pm0.129$ & $0.198\\pm0.131$ & $2.295\\pm1.185$ & $2.290\\pm1.186$ \\\\\n",
      "SL-MLP & $0.342\\pm0.067$ & $0.104\\pm0.038$ & $1.232\\pm0.277$ & $0.925\\pm0.224$ \\\\\n",
      "TL-MLP & $0.507\\pm0.208$ & $0.000\\pm0.000$ & $1.399\\pm0.496$ & $0.641\\pm0.190$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1586278/1854063471.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ate['selection'] = df_ate['ate_rs_lgbm']\n",
      "/tmp/ipykernel_1586278/1854063471.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pehe['selection'] = df_pehe['pehe_rs_lgbm']\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv(f'./tables/{ds}_compare_metrics_meta_base_sem_latex.csv')\n",
    "df_all['name'] = df_all['name'].apply(lambda x: x.upper().replace('_', '-'))\n",
    "\n",
    "df_ate = show_base(df_all, avg_metric, 'ate', plugin_models, rscore_base_models)\n",
    "df_pehe = show_base(df_all, ite_metric, 'pehe', plugin_models, rscore_base_models)\n",
    "\n",
    "df_ate['selection'] = df_ate['ate_rs_lgbm']\n",
    "df_pehe['selection'] = df_pehe['pehe_rs_lgbm']\n",
    "\n",
    "df_merged = df_ate.merge(df_pehe, on=['name'], suffixes=['_ate', '_pehe'])\n",
    "print(df_merged[['name', 'selection_ate', 'ate_test', 'selection_pehe', 'pehe_test']].to_latex(index=False, escape=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective -- model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "    selection &         all_ate &        all_pehe \\\\\n",
      "\\midrule\n",
      "          MSE & $0.188\\pm0.097$ & $0.786\\pm0.189$ \\\\\n",
      "           R2 & $0.352\\pm0.146$ & $0.922\\pm0.237$ \\\\\n",
      "    SL-DT-ATE & $1.455\\pm0.848$ & $3.327\\pm1.454$ \\\\\n",
      "  SL-LGBM-ATE & $4.791\\pm0.904$ & $6.998\\pm2.261$ \\\\\n",
      "    SL-KR-ATE & $1.430\\pm0.608$ & $2.868\\pm0.978$ \\\\\n",
      "    TL-DT-ATE & $0.201\\pm0.057$ & $1.873\\pm0.393$ \\\\\n",
      "  TL-LGBM-ATE & $0.237\\pm0.082$ & $1.983\\pm0.434$ \\\\\n",
      "    TL-KR-ATE & $0.409\\pm0.115$ & $1.796\\pm0.690$ \\\\\n",
      "   SL-DT-PEHE & $1.655\\pm1.269$ & $4.188\\pm2.652$ \\\\\n",
      " SL-LGBM-PEHE & $4.791\\pm0.904$ & $6.998\\pm2.261$ \\\\\n",
      "   SL-KR-PEHE & $1.652\\pm0.788$ & $4.438\\pm2.248$ \\\\\n",
      "   TL-DT-PEHE & $0.267\\pm0.125$ & $2.605\\pm1.433$ \\\\\n",
      " TL-LGBM-PEHE & $0.306\\pm0.173$ & $2.357\\pm1.014$ \\\\\n",
      "   TL-KR-PEHE & $0.209\\pm0.048$ & $1.341\\pm0.518$ \\\\\n",
      " MATCH-1K-ATE & $0.323\\pm0.098$ & $3.199\\pm1.585$ \\\\\n",
      " MATCH-3K-ATE & $0.176\\pm0.039$ & $1.640\\pm0.352$ \\\\\n",
      " MATCH-5K-ATE & $0.209\\pm0.065$ & $1.841\\pm0.478$ \\\\\n",
      "MATCH-1K-PEHE & $0.164\\pm0.067$ & $0.718\\pm0.239$ \\\\\n",
      "MATCH-3K-PEHE & $0.167\\pm0.068$ & $0.748\\pm0.245$ \\\\\n",
      "MATCH-5K-PEHE & $0.182\\pm0.069$ & $0.755\\pm0.239$ \\\\\n",
      "        RS-DT & $0.853\\pm0.128$ & $2.149\\pm0.657$ \\\\\n",
      "      RS-LGBM & $0.535\\pm0.207$ & $1.389\\pm0.498$ \\\\\n",
      "        RS-KR & $0.378\\pm0.106$ & $1.495\\pm0.633$ \\\\\n",
      "         BEST & $0.000\\pm0.000$ & $0.585\\pm0.198$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv(f'./tables/{ds}_compare_metrics_all_sem_latex.csv')\n",
    "\n",
    "df_ate = show_all(df_all, avg_metric, ['ate', 'pehe'], plugin_models, matching_ks, rscore_base_models)\n",
    "df_pehe = show_all(df_all, ite_metric, ['ate', 'pehe'], plugin_models, matching_ks, rscore_base_models)\n",
    "\n",
    "selection_models = [f'{pmm}_{pbm}_{pm}' for pmm in plugin_meta_models for pbm in plugin_base_models for pm in ['ate', 'pehe']] + [f'match_{k}k_{pm}' for k in matching_ks for pm in ['ate', 'pehe']] + [f'rs_{rbm}' for rbm in rscore_base_models]\n",
    "d_ate = {f'{avg_metric}_test': 'best', f'{avg_metric}_mse': 'mse', f'{avg_metric}_r2': 'r2'}\n",
    "d_pehe = {f'{ite_metric}_test': 'best', f'{ite_metric}_mse': 'mse', f'{ite_metric}_r2': 'r2'}\n",
    "for sm in selection_models:\n",
    "    d_ate[f'{avg_metric}_{sm}'] = sm\n",
    "    d_pehe[f'{ite_metric}_{sm}'] = sm\n",
    "\n",
    "df_ate = df_ate.rename(columns=d_ate)\n",
    "df_pehe = df_pehe.rename(columns=d_pehe)\n",
    "\n",
    "df_ate = df_ate.set_index('name').T\n",
    "df_pehe = df_pehe.set_index('name').T\n",
    "\n",
    "df_merged = df_ate.merge(df_pehe, left_index=True, right_index=True, suffixes=['_ate', '_pehe']).reset_index()\n",
    "\n",
    "df_merged['selection'] = df_merged['index'].apply(lambda x: x.upper().replace('_', '-'))\n",
    "print(df_merged[['selection', 'all_ate', 'all_pehe']].to_latex(index=False, escape=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JOBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plugin_meta_models = ['sl', 'tl']\n",
    "#plugin_base_models = ['dt', 'lgbm']\n",
    "plugin_base_models = ['dt', 'lgbm', 'kr']\n",
    "plugin_models = [f'{pmm}_{pbm}' for pmm in plugin_meta_models for pbm in plugin_base_models]\n",
    "matching_ks = [1, 3, 5]\n",
    "#rscore_base_models = ['dt', 'lgbm', 'cb']\n",
    "rscore_base_models = ['dt', 'lgbm', 'kr']\n",
    "\n",
    "ds = 'jobs'\n",
    "avg_metric = 'att'\n",
    "ite_metric = 'policy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective -- causal estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "  name &   selection_att &        att_test &   selection_pol &     policy_test \\\\\n",
      "\\midrule\n",
      "    SL & $0.066\\pm0.020$ & $0.003\\pm0.001$ & $0.261\\pm0.019$ & $0.158\\pm0.011$ \\\\\n",
      "    TL & $0.074\\pm0.023$ & $0.000\\pm0.000$ & $0.235\\pm0.019$ & $0.128\\pm0.012$ \\\\\n",
      " IPSWS & $0.077\\pm0.025$ & $0.024\\pm0.019$ & $0.245\\pm0.013$ & $0.158\\pm0.013$ \\\\\n",
      "   DRS & $0.075\\pm0.023$ & $0.001\\pm0.001$ & $0.240\\pm0.010$ & $0.149\\pm0.010$ \\\\\n",
      "  DMLS & $0.078\\pm0.023$ & $0.016\\pm0.005$ & $0.264\\pm0.014$ & $0.193\\pm0.012$ \\\\\n",
      "    XL & $0.077\\pm0.025$ & $0.003\\pm0.002$ & $0.233\\pm0.019$ & $0.153\\pm0.013$ \\\\\n",
      "    CF & $0.072\\pm0.021$ & $0.053\\pm0.022$ & $0.225\\pm0.016$ & $0.204\\pm0.017$ \\\\\n",
      "SL-MLP & $0.068\\pm0.022$ & $0.023\\pm0.019$ & $0.254\\pm0.018$ & $0.162\\pm0.010$ \\\\\n",
      "TL-MLP & $0.066\\pm0.026$ & $0.010\\pm0.010$ & $0.226\\pm0.014$ & $0.132\\pm0.009$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1586278/3666940764.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_att['selection'] = df_att.apply(att_filter, axis=1)\n",
      "/tmp/ipykernel_1586278/3666940764.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pol['selection'] = df_pol.apply(policy_filter, axis=1)\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv(f'./tables/{ds}_compare_metrics_meta_est_sem_latex.csv')\n",
    "df_all['name'] = df_all['name'].apply(lambda x: x.upper().replace('_', '-'))\n",
    "\n",
    "df_att = show_est(df_all, avg_metric, 'ate', plugin_models, rscore_base_models)\n",
    "df_pol = show_est(df_all, ite_metric, 'pehe', plugin_models, rscore_base_models)\n",
    "\n",
    "df_att['selection'] = df_att.apply(att_filter, axis=1)\n",
    "df_pol['selection'] = df_pol.apply(policy_filter, axis=1)\n",
    "\n",
    "df_merged = df_att.merge(df_pol, on=['name'], suffixes=['_att', '_pol'])\n",
    "\n",
    "print(df_merged[['name', 'selection_att', 'att_test', 'selection_pol', 'policy_test']].to_latex(index=False, escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective -- base learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "  name &   selection_att &        att_test &   selection_pol &     policy_test \\\\\n",
      "\\midrule\n",
      "    L1 & $0.093\\pm0.024$ & $0.032\\pm0.022$ & $0.270\\pm0.024$ & $0.197\\pm0.013$ \\\\\n",
      "    L2 & $0.082\\pm0.025$ & $0.061\\pm0.023$ & $0.224\\pm0.019$ & $0.199\\pm0.014$ \\\\\n",
      "    DT & $0.062\\pm0.019$ & $0.002\\pm0.001$ & $0.233\\pm0.019$ & $0.142\\pm0.010$ \\\\\n",
      "    RF & $0.074\\pm0.021$ & $0.011\\pm0.006$ & $0.239\\pm0.017$ & $0.155\\pm0.015$ \\\\\n",
      "    ET & $0.073\\pm0.023$ & $0.014\\pm0.008$ & $0.223\\pm0.016$ & $0.148\\pm0.013$ \\\\\n",
      "    KR & $0.085\\pm0.026$ & $0.000\\pm0.000$ & $0.262\\pm0.024$ & $0.141\\pm0.009$ \\\\\n",
      "    CB & $0.066\\pm0.021$ & $0.025\\pm0.011$ & $0.212\\pm0.015$ & $0.156\\pm0.011$ \\\\\n",
      "  LGBM & $0.076\\pm0.024$ & $0.009\\pm0.003$ & $0.221\\pm0.015$ & $0.174\\pm0.011$ \\\\\n",
      "    CF & $0.072\\pm0.021$ & $0.053\\pm0.022$ & $0.225\\pm0.016$ & $0.204\\pm0.017$ \\\\\n",
      "SL-MLP & $0.075\\pm0.025$ & $0.023\\pm0.019$ & $0.251\\pm0.014$ & $0.162\\pm0.010$ \\\\\n",
      "TL-MLP & $0.088\\pm0.025$ & $0.010\\pm0.010$ & $0.216\\pm0.015$ & $0.132\\pm0.009$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1586278/3844730419.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_att['selection'] = df_att['att_rs_lgbm']\n",
      "/tmp/ipykernel_1586278/3844730419.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pol['selection'] = df_pol['policy_rs_lgbm']\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv(f'./tables/{ds}_compare_metrics_meta_base_sem_latex.csv')\n",
    "df_all['name'] = df_all['name'].apply(lambda x: x.upper().replace('_', '-'))\n",
    "\n",
    "df_att = show_base(df_all, avg_metric, 'ate', plugin_models, rscore_base_models)\n",
    "df_pol = show_base(df_all, ite_metric, 'pehe', plugin_models, rscore_base_models)\n",
    "\n",
    "df_att['selection'] = df_att['att_rs_lgbm']\n",
    "df_pol['selection'] = df_pol['policy_rs_lgbm']\n",
    "\n",
    "df_merged = df_att.merge(df_pol, on=['name'], suffixes=['_att', '_pol'])\n",
    "\n",
    "print(df_merged[['name', 'selection_att', 'att_test', 'selection_pol', 'policy_test']].to_latex(index=False, escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective -- model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "    selection &         all_att &         all_pol \\\\\n",
      "\\midrule\n",
      "          MSE & $0.077\\pm0.025$ & $0.245\\pm0.013$ \\\\\n",
      "           R2 & $0.072\\pm0.022$ & $0.257\\pm0.019$ \\\\\n",
      "          POL & $0.300\\pm0.090$ & $0.220\\pm0.016$ \\\\\n",
      "    SL-DT-ATE & $0.080\\pm0.026$ & $0.275\\pm0.024$ \\\\\n",
      "  SL-LGBM-ATE & $0.075\\pm0.025$ & $0.267\\pm0.015$ \\\\\n",
      "    SL-KR-ATE & $0.068\\pm0.022$ & $0.233\\pm0.023$ \\\\\n",
      "    TL-DT-ATE & $0.086\\pm0.026$ & $0.245\\pm0.017$ \\\\\n",
      "  TL-LGBM-ATE & $0.081\\pm0.027$ & $0.250\\pm0.016$ \\\\\n",
      "    TL-KR-ATE & $0.066\\pm0.013$ & $0.222\\pm0.010$ \\\\\n",
      "   SL-DT-PEHE & $0.083\\pm0.026$ & $0.297\\pm0.020$ \\\\\n",
      " SL-LGBM-PEHE & $0.083\\pm0.026$ & $0.296\\pm0.020$ \\\\\n",
      "   SL-KR-PEHE & $0.076\\pm0.024$ & $0.248\\pm0.018$ \\\\\n",
      "   TL-DT-PEHE & $0.065\\pm0.022$ & $0.248\\pm0.016$ \\\\\n",
      " TL-LGBM-PEHE & $0.073\\pm0.022$ & $0.247\\pm0.015$ \\\\\n",
      "   TL-KR-PEHE & $0.085\\pm0.023$ & $0.244\\pm0.015$ \\\\\n",
      " MATCH-1K-ATE & $0.161\\pm0.076$ & $0.229\\pm0.018$ \\\\\n",
      " MATCH-3K-ATE & $0.158\\pm0.077$ & $0.227\\pm0.014$ \\\\\n",
      " MATCH-5K-ATE & $0.160\\pm0.077$ & $0.236\\pm0.021$ \\\\\n",
      "MATCH-1K-PEHE & $0.080\\pm0.028$ & $0.235\\pm0.014$ \\\\\n",
      "MATCH-3K-PEHE & $0.067\\pm0.024$ & $0.235\\pm0.010$ \\\\\n",
      "MATCH-5K-PEHE & $0.073\\pm0.028$ & $0.241\\pm0.009$ \\\\\n",
      "        RS-DT & $0.072\\pm0.019$ & $0.220\\pm0.012$ \\\\\n",
      "      RS-LGBM & $0.075\\pm0.019$ & $0.224\\pm0.017$ \\\\\n",
      "        RS-KR & $0.080\\pm0.023$ & $0.234\\pm0.014$ \\\\\n",
      "         BEST & $0.000\\pm0.000$ & $0.121\\pm0.011$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv(f'./tables/{ds}_compare_metrics_all_sem_latex.csv')\n",
    "\n",
    "df_ate = show_all_jobs(df_all, avg_metric, ['ate', 'pehe'], plugin_models, matching_ks, rscore_base_models)\n",
    "df_pehe = show_all_jobs(df_all, ite_metric, ['ate', 'pehe'], plugin_models, matching_ks, rscore_base_models)\n",
    "\n",
    "selection_models = [f'{pmm}_{pbm}_{pm}' for pmm in plugin_meta_models for pbm in plugin_base_models for pm in ['ate', 'pehe']] + [f'match_{k}k_{pm}' for k in matching_ks for pm in ['ate', 'pehe']] + [f'rs_{rbm}' for rbm in rscore_base_models]\n",
    "d_ate = {f'{avg_metric}_test': 'best', f'{avg_metric}_mse': 'mse', f'{avg_metric}_r2': 'r2', f'{avg_metric}_pol': 'pol'}\n",
    "d_pehe = {f'{ite_metric}_test': 'best', f'{ite_metric}_mse': 'mse', f'{ite_metric}_r2': 'r2', f'{ite_metric}_pol': 'pol'}\n",
    "for sm in selection_models:\n",
    "    d_ate[f'{avg_metric}_{sm}'] = sm\n",
    "    d_pehe[f'{ite_metric}_{sm}'] = sm\n",
    "\n",
    "df_ate = df_ate.rename(columns=d_ate)\n",
    "df_pehe = df_pehe.rename(columns=d_pehe)\n",
    "\n",
    "df_ate = df_ate.set_index('name').T\n",
    "df_pehe = df_pehe.set_index('name').T\n",
    "\n",
    "df_merged = df_ate.merge(df_pehe, left_index=True, right_index=True, suffixes=['_att', '_pol']).reset_index()\n",
    "\n",
    "df_merged['selection'] = df_merged['index'].apply(lambda x: x.upper().replace('_', '-'))\n",
    "print(df_merged[['selection', 'all_att', 'all_pol']].to_latex(index=False, escape=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b92bf4d768b2900bfdb0d55b9270dc3e0484f7baa07f8baf2ad16a5c3cba66ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
